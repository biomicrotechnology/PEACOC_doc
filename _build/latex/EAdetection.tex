%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{EAdetection Documentation}
\date{Jan 27, 2021}
\release{1.0}
\author{Katharina Heining}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\maketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


EAdetection is a tool that allows you to automatically \sphinxstylestrong{detected and classify epilepitiform activity (EA) patterns}.
If transform a local field potential (LFP) recording in a sequence of classified spike bursts and solitary spikes.
The tool is python-based and you can execute it via the command-line.

The EA patterns EAdetection identifies are:
\begin{itemize}
\item {} 
\sphinxstyleemphasis{high-load bursts}, these comprise large behavioral seizures and paroxysmal and seizure-like activity (e.g. high-voltagesharp waves and hyperparoxysmal discharges)

\item {} 
\sphinxstyleemphasis{medium-load bursts}, a category bridging the continuum between high-load and low-load bursts

\item {} 
\sphinxstyleemphasis{low-load bursts}, which are looser trains of epileptiform spikes

\end{itemize}

Three \sphinxstylestrong{major analysis steps} are involved: I) preprocessing (resampling, assigning the polarity,
semiautomatic artifact detection), II) transforming the LFP into a train of epileptiform spikes, and III)
transforming the spike train into a sequence of classified spike bursts.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{fig6_codeflow}.png}\hspace*{\fill}}

The tool was originally developed for the \sphinxstylestrong{intrahippocampal kainate mouse model}, but we have seen promising results for
other animal models of epilepsy as well. It has been used in several publications, but you will find the method best described
in \sphinxstyleemphasis{Heining et al. (2021)\_}.

In this documentation you will learn how to {\hyperref[\detokenize{getting_started:getting-started}]{\sphinxcrossref{\DUrole{std,std-ref}{set everything up}}}}, {\hyperref[\detokenize{setting_parameters:setting-parameters}]{\sphinxcrossref{\DUrole{std,std-ref}{set the parameters}}}},
run the {\hyperref[\detokenize{preprocessing:preprocessing}]{\sphinxcrossref{\DUrole{std,std-ref}{preprocessing}}}} and the {\hyperref[\detokenize{LFP_to_bursts:lfp-to-bursts}]{\sphinxcrossref{\DUrole{std,std-ref}{actual analyses}}}}, {\hyperref[\detokenize{access_results:access-results}]{\sphinxcrossref{\DUrole{std,std-ref}{harvest the results}}}},
and {\hyperref[\detokenize{access_metadata:access-metadata}]{\sphinxcrossref{\DUrole{std,std-ref}{retrieve metadata and diagnostic metrics}}}}.
You can download the example data and the files successively generated in this tutorial from \sphinxstyleemphasis{here\_}.
If can also download a \sphinxstyleemphasis{pdf-version\_} of this documentation.

\begin{sphinxadmonition}{note}{\label{index:index-0}Todo:}\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Make a link to Heining et al. 2021 once the paper is out.

\item {} 
Make a link to the tutorial data file.

\item {} 
Make a link to the pdf.

\end{enumerate}
\end{sphinxadmonition}


\chapter{Getting started}
\label{\detokenize{getting_started:getting-started}}\label{\detokenize{getting_started:id1}}\label{\detokenize{getting_started::doc}}

\section{Download the toolbox}
\label{\detokenize{getting_started:download-the-toolbox}}\label{\detokenize{getting_started:download}}

\subsection{Using git}
\label{\detokenize{getting_started:using-git}}\label{\detokenize{getting_started:download-git}}
Navigate to where you want to store the toolbox. For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{cd} \PYG{n}{EAdetection\PYGZus{}tutorial}\PYG{o}{/}
\end{sphinxVerbatim}

Then clone the repository from git using the command-line:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{git} \PYG{n}{clone} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{biomicrotechnology}\PYG{o}{/}\PYG{n}{EAdetection}\PYG{o}{.}\PYG{n}{git}
\end{sphinxVerbatim}

The output on the command-line should look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{remote}\PYG{p}{:} \PYG{n}{Enumerating} \PYG{n}{objects}\PYG{p}{:} \PYG{l+m+mi}{362}\PYG{p}{,} \PYG{n}{done}\PYG{o}{.}
\PYG{n}{remote}\PYG{p}{:} \PYG{n}{Counting} \PYG{n}{objects}\PYG{p}{:} \PYG{l+m+mi}{100}\PYG{o}{\PYGZpc{}} \PYG{p}{(}\PYG{l+m+mi}{362}\PYG{o}{/}\PYG{l+m+mi}{362}\PYG{p}{)}\PYG{p}{,} \PYG{n}{done}\PYG{o}{.}
\PYG{n}{remote}\PYG{p}{:} \PYG{n}{Compressing} \PYG{n}{objects}\PYG{p}{:} \PYG{l+m+mi}{100}\PYG{o}{\PYGZpc{}} \PYG{p}{(}\PYG{l+m+mi}{151}\PYG{o}{/}\PYG{l+m+mi}{151}\PYG{p}{)}\PYG{p}{,} \PYG{n}{done}\PYG{o}{.}
\PYG{n}{remote}\PYG{p}{:} \PYG{n}{Total} \PYG{l+m+mi}{362} \PYG{p}{(}\PYG{n}{delta} \PYG{l+m+mi}{216}\PYG{p}{)}\PYG{p}{,} \PYG{n}{reused} \PYG{l+m+mi}{340} \PYG{p}{(}\PYG{n}{delta} \PYG{l+m+mi}{201}\PYG{p}{)}\PYG{p}{,} \PYG{n}{pack}\PYG{o}{\PYGZhy{}}\PYG{n}{reused} \PYG{l+m+mi}{0}
\PYG{n}{Receiving} \PYG{n}{objects}\PYG{p}{:} \PYG{l+m+mi}{100}\PYG{o}{\PYGZpc{}} \PYG{p}{(}\PYG{l+m+mi}{362}\PYG{o}{/}\PYG{l+m+mi}{362}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mf}{298.16} \PYG{n}{KiB} \PYG{o}{\textbar{}} \PYG{l+m+mi}{0} \PYG{n+nb}{bytes}\PYG{o}{/}\PYG{n}{s}\PYG{p}{,} \PYG{n}{done}\PYG{o}{.}
\PYG{n}{Resolving} \PYG{n}{deltas}\PYG{p}{:} \PYG{l+m+mi}{100}\PYG{o}{\PYGZpc{}} \PYG{p}{(}\PYG{l+m+mi}{216}\PYG{o}{/}\PYG{l+m+mi}{216}\PYG{p}{)}\PYG{p}{,} \PYG{n}{done}\PYG{o}{.}
\PYG{n}{Checking} \PYG{n}{connectivity}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{done}\PYG{o}{.}
\end{sphinxVerbatim}

Now you have a sub-folder called \sphinxstyleemphasis{EAdetection} in the directory where you executed git clone.
\sphinxstyleemphasis{EAdetection} contains all the code.


\subsubsection{Updating to a newer version}
\label{\detokenize{getting_started:updating-to-a-newer-version}}\label{\detokenize{getting_started:update-git}}
You can later update the toolbox to its newest version using git.
Navigate to the toolbox directory:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{cd} \PYG{n}{EAdetection}
\end{sphinxVerbatim}

And then update to the newest version of the code:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{git} \PYG{n}{pull}
\end{sphinxVerbatim}

But for now, let’s stay one level above the folder \sphinxstyleemphasis{EAdetection}.


\subsection{Alternative: download archive}
\label{\detokenize{getting_started:alternative-download-archive}}\label{\detokenize{getting_started:download-zip}}
If you do not want to use git, you can also download the \sphinxhref{https://github.com/biomicrotechnology/EAdetection/archive/master.zip}{zip archive} from github.
Extract this to a place where you want to store the toolbox.


\section{Set up a virtual environment (recommended)}
\label{\detokenize{getting_started:set-up-a-virtual-environment-recommended}}\label{\detokenize{getting_started:virtual-env}}
I strongly recommened installing all requirements for \sphinxstyleemphasis{EAdetection} in a new virtual environment and always run the program from there.
This keeps all dependencies nice and tidy and prevents that stuff does not work anymore due to an annoying update.
Here is how to set up a virtual environment.
To use virtual environments, use this command on Linux:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{pip} \PYG{n}{install} \PYG{n}{virtualenvwrapper}
\end{sphinxVerbatim}

Or this on for a Windows machine:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{pip} \PYG{n}{install} \PYG{n}{virtualenvwrapper}\PYG{o}{\PYGZhy{}}\PYG{n}{win}
\end{sphinxVerbatim}

Then create a virtual environment and let’s name it \sphinxstyleemphasis{EAdetectionEnv}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{mkvirtualenv} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{python}\PYG{o}{=}\PYG{n}{python3} \PYG{n}{EAdetectionEnv}
\end{sphinxVerbatim}

To enter this environment, type:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{workon} \PYG{n}{EAdetectionEnv}
\end{sphinxVerbatim}

You can leave this environment by typing:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{deactivate}
\end{sphinxVerbatim}

But for now, let’s stay in \sphinxstyleemphasis{EAdetectionEnv}.


\section{Install requirements}
\label{\detokenize{getting_started:install-requirements}}\label{\detokenize{getting_started:requirements}}
If you do not have python 3 (code also works with python version \textgreater{}=2.5) and pip 3 on your computer.
You can find instructions about how to install these two at \sphinxhref{https://realpython.com/installing-python/}{python} and \sphinxhref{https://pip.pypa.io/en/stable/}{pip}.

If you decided to use a virtual environment for EA detection, make sure you are in it:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{workon} \PYG{n}{EAdetectionEnv}
\end{sphinxVerbatim}

Install the requirements:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{pip3} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{n}{r} \PYG{n}{EAdetection}\PYG{o}{/}\PYG{n}{requirements}\PYG{o}{.}\PYG{n}{txt}
\end{sphinxVerbatim}


\chapter{Setting parameters}
\label{\detokenize{setting_parameters:setting-parameters}}\label{\detokenize{setting_parameters:id1}}\label{\detokenize{setting_parameters::doc}}

\section{How parameters are handled}
\label{\detokenize{setting_parameters:how-parameters-are-handled}}\label{\detokenize{setting_parameters:param-intro}}
Parameters are handled at two different levels. The \sphinxstylestrong{default parameters} are located at
\sphinxstyleemphasis{EAdetection/config/configAnalysis.yml} and look like this:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{configAnalysis}.png}\hspace*{\fill}}

Behind each parameter and default value there is an explanation of what it is good for.
Make a change to this file only if you are absolutely sure that you want this change for all
for all of your analyses. For now, leave it untouched.
In the next sections we will create experiment and recording specific parameter files where you
can overwrite the defaults.


\section{Create a template}
\label{\detokenize{setting_parameters:create-a-template}}\label{\detokenize{setting_parameters:param-template}}
We found it very useful and time-saving to create parameter templates for whole experiments, i.e. a larger number of
recordings to which the same parameters should be applied.
To work with templates, first create a directory where you would like to store your templates:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{mkdir} \PYG{n}{my\PYGZus{}templates}
\end{sphinxVerbatim}

Then copy a templates from EAdetection/templates to your directory. On Linux:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{cp} \PYG{n}{EAdetection}\PYG{o}{/}\PYG{n}{templates}\PYG{o}{/}\PYG{n}{template\PYGZus{}\PYGZus{}runparams}\PYG{o}{.}\PYG{n}{yml} \PYG{n}{my\PYGZus{}templates}\PYG{o}{/}\PYG{n}{template\PYGZus{}experiment1}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

On Windows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{cp} \PYG{n}{EAdetection}\PYG{o}{/}\PYG{n}{templates}\PYG{o}{/}\PYG{n}{template\PYGZus{}runparamsWin}\PYG{o}{.}\PYG{n}{yml} \PYG{n}{my\PYGZus{}templates}\PYG{o}{/}\PYG{n}{template\PYGZus{}experiment1}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

Open the copied template (in this case \sphinxstyleemphasis{my\_templates/template\_experiment1.yml}), it looks like this:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{my_template_unedited}.png}\hspace*{\fill}}

All entries in CAPITALS are place-holders, which we will now successively replace according to our setup and
preferences:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{my_template_findReplace2}.png}\hspace*{\fill}}
\phantomsection\label{\detokenize{setting_parameters:replacement-params}}
Make the following replacements:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{PACKAGE\_DIR}}: where you cloned/downloaded the toolbox, e.g.: \sphinxcode{\sphinxupquote{home/weltgeischt/EAdetection\_tutorial}}

\item {} 
\sphinxcode{\sphinxupquote{DATADIR}} \(\rightarrow\) where you want your results saved, e.g.: \sphinxcode{\sphinxupquote{home/weltgeischt/EAdetection\_tutorial/my\_results/data}}

\item {} 
\sphinxcode{\sphinxupquote{FIGDIR}}: where you want the figures saved, e.g.: \sphinxcode{\sphinxupquote{home/weltgeischt/EAdetection\_tutorial/my\_results/figures}}

\item {} 
\sphinxcode{\sphinxupquote{SOURCEDIR}}: directory in which you keep your raw data files, e.g.: \sphinxcode{\sphinxupquote{home/weltgeischt/EAdetection\_tutorial/example\_data}}

\end{itemize}


\subsection{Overwriting defaults}
\label{\detokenize{setting_parameters:overwriting-defaults}}\label{\detokenize{setting_parameters:overwrite-defaults}}
You can also overwrite default parameters at the template level. You do this by specifying the parameter as a sub-entry
below \sphinxstyleemphasis{setparams} (red arrows in example below).
Here we set the offset for spike detection (\sphinxstyleemphasis{EdDetection}, Ed for epileptiform discharge) to 300 s, i.e. we exclude
the first 5 min of the recording from spike detection:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{my_template_editParameters}.png}\hspace*{\fill}}

At this stage we have created a template for a big batch of recordings.


\section{Create a parameter file for a recording}
\label{\detokenize{setting_parameters:create-a-parameter-file-for-a-recording}}\label{\detokenize{setting_parameters:param-rec}}
Now we will create a parameter file specific for a single recording session. This will be the input fort the commandline
tool. Herey ou will learn how to generate a specific parameter file from the template and how edit it.
But first, let’s create a directory where you can store all your specific parameter files:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{mkdir} \PYG{n}{run\PYGZus{}params}
\end{sphinxVerbatim}

Using \sphinxstyleemphasis{generate\_ymlsetup} you can automatically generate the recording specific parameter file and
set the recording id and source file from which to import the raw data (it basically does a find-replace for
\sphinxcode{\sphinxupquote{ANIMAL\_BLOCK\_ELECTRODE}} and \sphinxcode{\sphinxupquote{THIS\_SOURCE\_FILE}} in your template).
First, you enter the toolbox and call python or ipython:

\textgreater{} cd EAdetection
\textgreater{} ipython

In python you can now generate your recording specific parameter file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{core}\PYG{n+nn}{.}\PYG{n+nn}{helpers} \PYG{k}{import} \PYG{n}{generate\PYGZus{}ymlsetup}
\PYG{n}{template\PYGZus{}path} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/weltgeischt/EAdetection\PYGZus{}tutorial/my\PYGZus{}templates/template\PYGZus{}experiment1.yml}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{rec\PYGZus{}id} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{my\PYGZus{}recording}\PYG{l+s+s1}{\PYGZsq{}} \PYG{c+c1}{\PYGZsh{} I recommend using animalID\PYGZus{}elecID\PYGZus{}recID (eg AN115\PYGZus{}El2\PYGZus{}rec5)}
\PYG{n}{datasource} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{my\PYGZus{}example\PYGZus{}data.smr}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{n}{setuppath} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/weltgeischt/EAdetection\PYGZus{}tutorial/run\PYGZus{}params/}\PYG{l+s+si}{\PYGZpc{}s}\PYG{l+s+s1}{\PYGZus{}params.yml}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{\PYGZpc{}}\PYG{n}{rec\PYGZus{}id}
\PYG{n}{generate\PYGZus{}ymlsetup}\PYG{p}{(}\PYG{n}{rec\PYGZus{}id}\PYG{p}{,} \PYG{n}{datasource}\PYG{p}{,}\PYG{n}{template\PYGZus{}path}\PYG{p}{,}\PYG{n}{setuppath}\PYG{o}{=}\PYG{n}{setuppath}\PYG{p}{)}
\PYG{n}{exit}\PYG{p}{(}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}to leave python}
\end{sphinxVerbatim}

In this case \sphinxstyleemphasis{rec\_id} is the id of the recording. I recommend to give it some meaningful name specifying the animal, electrode
and number of recording. You can \sphinxstyleemphasis{download this example .smr file\_} to replicate what happens
in this tutorial.
The variable \sphinxstyleemphasis{setuppath} specifies where the recording specific parameter file will be saved.
Et voilà, now you have created your recording specific parameter file at \sphinxstyleemphasis{run\_params/my\_recording\_params.yml}.

You can edit further edit your recording specific parameter file by hand in the same way as :ref:{}` described previously for the template \textless{}overwrite\_defaults\textgreater{}{}`.

\begin{sphinxadmonition}{note}{Note:}
Have a look at \sphinxstyleemphasis{EAdetection/examples/generate\_paramfile.py} for creating several parameter files
in a loop.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{\label{setting_parameters:index-0}Todo:}
Make a link to \sphinxstyleemphasis{download this example .smr file\_}.
\end{sphinxadmonition}

\sphinxstylestrong{Alternative}: If you don’t like python, you can of course find/replace \sphinxcode{\sphinxupquote{ANIMAL\_BLOCK\_ELECTRODE}} and \sphinxcode{\sphinxupquote{THIS\_SOURCE\_FILE}} by hand too.


\chapter{Preprocessing}
\label{\detokenize{preprocessing:preprocessing}}\label{\detokenize{preprocessing:id1}}\label{\detokenize{preprocessing::doc}}
Both preprocessing and {\hyperref[\detokenize{LFP_to_bursts:lfp-to-bursts}]{\sphinxcrossref{\DUrole{std,std-ref}{EA detection and classification}}}} work as a command line tool. The basic command structure is like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{o}{\PYGZlt{}}\PYG{n}{path}\PYG{o}{/}\PYG{n}{to}\PYG{o}{/}\PYG{n}{codefile}\PYG{o}{.}\PYG{n}{py}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{path}\PYG{o}{/}\PYG{n}{to}\PYG{o}{/}\PYG{n}{paramfile}\PYG{o}{.}\PYG{n}{yml}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}


\section{Load and resample}
\label{\detokenize{preprocessing:load-and-resample}}\label{\detokenize{preprocessing:resample}}
The goal of this is to transfer obtain a resampled version of the raw data in hdf5 format. To date the loading supports
.smr and .edf files.

Just run:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{rawToResampled}\PYG{o}{.}\PYG{n}{py} \PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

Depending on what you put in your specific parameter file, loading and resampling either just run through {\hyperref[\detokenize{preprocessing:auto-load}]{\sphinxcrossref{\DUrole{std,std-ref}{automatically}}}}, which is nice when processing
several recordings in a loop, or you can select the channel {\hyperref[\detokenize{preprocessing:interactive-load}]{\sphinxcrossref{\DUrole{std,std-ref}{interactively}}}}.


\subsection{Automatic mode}
\label{\detokenize{preprocessing:automatic-mode}}\label{\detokenize{preprocessing:auto-load}}
For this you need to know the channel you want to access and enter it directly in the parameter file:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{resample_channel_params}.png}\hspace*{\fill}}


\subsection{Alternative: Interactive mode}
\label{\detokenize{preprocessing:alternative-interactive-mode}}\label{\detokenize{preprocessing:interactive-load}}
In case you do not know the channel name and want to select a channel interactively, \sphinxstyleemphasis{channel} should be set to \sphinxstyleemphasis{interactive}
in the specific parameter file:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{resample_interactive_params}.png}\hspace*{\fill}}

In interactive mode you then type the name of the channel you want to select and exit with \sphinxcode{\sphinxupquote{d}}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=350\sphinxpxdimen]{{resample_interactive}.png}\hspace*{\fill}}

You now have created a resampled .hdf5 at \sphinxstyleemphasis{/my\_results/data/my\_recording/} and a log-file of the analysis (which is nice for handing
in, in case your analysis is not working properly):

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{resampled_file_and_log_created}.png}\hspace*{\fill}}

\begin{sphinxadmonition}{note}{Note:}
You can skip this loading and resampling routine and use your own resampled hdf5 file. Take care, however, to
adhere to the format given in \sphinxstyleemphasis{EAdetection\_tutorial/my\_results/data/my\_recording/my\_recording\_\_raw500.h5}
\end{sphinxadmonition}


\section{Assign polarity}
\label{\detokenize{preprocessing:assign-polarity}}\label{\detokenize{preprocessing:polarity}}
Polarity refers to the direction of the spike component in EA. To interactively determine and set the polarity of your
recording, run the following command:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{polarityCheck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

Two windows will pop up: A LFP trace of the whole recording…

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{polarity_trace}.png}\hspace*{\fill}}

… and an amplitude distribution, with checkboxes:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{polarity_click}.png}\hspace*{\fill}}

In this example you can see a shoulder at negative amplitudes, this strongly suggests, that the polarity of this
example recording is negative. To be sure you could also zoom around in the LFP trace that just popped up. As you can see,
the polarity indeed appears to be negative (the spike component goes down).

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{polarity_traceZoom}.png}\hspace*{\fill}}

By marking a checkbox in the upper right corner of the window with the amplitude distribution,
you select a polarity. Clicking \sphinxcode{\sphinxupquote{Done}} (bottom right) ends the whole procedure, and a simple .txt file is created
at \sphinxstyleemphasis{EAdetection\_tutorial/my\_results/data/my\_recording/my\_recording\_\_polarity.txt}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=300\sphinxpxdimen]{{polarity_file}.png}\hspace*{\fill}}

\begin{sphinxadmonition}{note}{Note:}
If you know the polarity of your recordings anyway, you can yourself create a file \sphinxstyleemphasis{my\_recording\_\_polarity.txt} and
do not need to follow the interactive routine to determine the polarity.  If the file \sphinxstyleemphasis{my\_recording\_\_polarity.txt} is not present,
later analyses will assume default polarity (negative).
\end{sphinxadmonition}


\section{Detect artifacts}
\label{\detokenize{preprocessing:detect-artifacts}}\label{\detokenize{preprocessing:artifacts}}
To run the semi-automatic artifact detection, execute this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{artifactCheck}\PYG{o}{.}\PYG{n}{py} \PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

A window displaying the whole extent of the recording session will pop up. In it single events the algorithm detected
as potential \sphinxstyleemphasis{saturation artifacts} are marked by \sphinxcode{\sphinxupquote{red dots}} and potential \sphinxstyleemphasis{longer stretches of artifacts} are marked by \sphinxcode{\sphinxupquote{purple lines}}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{arts_trace}.png}\hspace*{\fill}}

\sphinxstylestrong{Accepting suggested artifacts:} Zoom around to have a look whether you want to accept any of the proposed artifacts. Accepting an artifact means that this
stretch of data (plus a margin for the \sphinxstyleemphasis{saturation artifact}) will be masked for further analyses. To accept an artifact,
\sphinxcode{\sphinxupquote{double left click}} on its marker. Once you accepted the artifact its marker will turn \sphinxcode{\sphinxupquote{yellow}}.

\sphinxstylestrong{Rejecting suggested artifacts:} \sphinxcode{\sphinxupquote{double right click}} to reject a suggested artifact. Once rejected, the marker of the artifact will turn \sphinxcode{\sphinxupquote{blue}}:

\begin{sphinxadmonition}{warning}{Warning:}
Only artifacts marked in yellow, i.e. accepted artifacts, will be saved as artifacts. The functionality of rejecting artifacts is just there
to better keep track of which artifacts you accepted. By default, all potential artifacts the algorithm highlights will not be masked in later analyses
unless you explicitly accept them.
\end{sphinxadmonition}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{arts_accepted_rejected}.png}\hspace*{\fill}}

\begin{sphinxadmonition}{note}{Note:}
Make sure to release the zoom tool (by clicking on it), once you try to accept/reject artifacts. Otherwise selection
will not work.
\end{sphinxadmonition}

\sphinxstylestrong{Adding artifacts yourself:} To add a single artifact event \sphinxcode{\sphinxupquote{double middle click}} at the position where you have identified it. A \sphinxcode{\sphinxupquote{yellow dot}} will appear.
For adding longer stretches of artifacts \sphinxcode{\sphinxupquote{double left click}} at the position where you think the artifact starts and then \sphinxcode{\sphinxupquote{single left click}}
where you think the artifact ends. This artifact stretch will be indicated by a yellow line. We typically exclude large stretches of data in that way
when they appear to be peppered by artifacts.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{arts_added}.png}\hspace*{\fill}}

\begin{sphinxadmonition}{important}{Important:}
For adding your own artifacts, always \sphinxstylestrong{click below y=0}. This serves to keep self-identified and automatically suggested artifacts separate.
\end{sphinxadmonition}

Once you are finished with artifact hunting, click on the blue \sphinxcode{\sphinxupquote{Done}} button. Again a simple .txt file is created at
\sphinxstyleemphasis{EAdetection\_tutorial/my\_results/data/my\_recording/my\_recording\_\_artifacts.txt}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=300\sphinxpxdimen]{{arts_file}.png}\hspace*{\fill}}

Below the header \sphinxcode{\sphinxupquote{(artstart,artstop)}} the start and end points of large artifact stretches are indicated (yellow lines in the GUI, see above). Below the header
\sphinxcode{\sphinxupquote{saturation artifacts}} time points of single artifact events are given (yellow dots in the GUI). Don’t worry if some artifact stretches overlap in time (as shown in this example)
- the tool can resolve this automatically.

\phantomsection\label{\detokenize{preprocessing:adding-artifacts-manually}}
\begin{sphinxadmonition}{note}{Note:}
You can edit the file \sphinxstyleemphasis{my\_recording\_\_artifacts.txt} by hand or altogether avoid the interactive routine described here and create such a file yourself.
If the file \sphinxstyleemphasis{my\_recording\_\_artifacts.txt} is not present, later analyses will assume that there are no artifacts.
\end{sphinxadmonition}


\chapter{EA detection and classification}
\label{\detokenize{LFP_to_bursts:ea-detection-and-classification}}\label{\detokenize{LFP_to_bursts:lfp-to-bursts}}\label{\detokenize{LFP_to_bursts::doc}}
Spike detection and burst detection/classification are called with a single command. If you are not interested in bursts and
prefer to just run the spike detection you can do so by excluding \sphinxtitleref{BurstClassificaton} from the list of \sphinxtitleref{analysis:run} in
the parameter file at the template or recording specific level (see {\hyperref[\detokenize{setting_parameters:setting-parameters}]{\sphinxcrossref{\DUrole{std,std-ref}{Setting parameters}}}}):

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{setting_run}.png}\hspace*{\fill}}

{\hyperref[\detokenize{LFP_to_bursts:spike-detection}]{\sphinxcrossref{\DUrole{std,std-ref}{Spike detection}}}} is followed by {\hyperref[\detokenize{LFP_to_bursts:burst-classification}]{\sphinxcrossref{\DUrole{std,std-ref}{burst classification}}}}.
Spike detection consists of three consecutive steps: \sphinxstyleemphasis{spectral spike detection} (the main step) complemented by
\sphinxstyleemphasis{amplitude based spike detection} for reducing false negatives and \sphinxstyleemphasis{spike sorting} for reducing false positives.
Amplitude based spike detection and burst classificaton runs fully automatically.
For spectral spike detection and spike sorting there is a \sphinxstylestrong{GUI} that allows you to set parameters manually.
Depending on whether you want to use the GUI or rely on default parameters, have \sphinxtitleref{interactive} set to True or False in the
parameter file:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=300\sphinxpxdimen]{{setting_interactive}.png}\hspace*{\fill}}

Execute the spike detection and burst classification through the command-line:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{LFPtoBursts}\PYG{o}{.}\PYG{n}{py} \PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

Now your PC may be busy for a few minutes (about 3 min for a 2h recording on an ok Laptop). If you chose not to use a GUI (interactive:False)
nothing will pop up and you can skip forward to {\hyperref[\detokenize{output:output}]{\sphinxcrossref{\DUrole{std,std-ref}{Output}}}}:


\section{Spike detection}
\label{\detokenize{LFP_to_bursts:spike-detection}}\label{\detokenize{LFP_to_bursts:id1}}

\subsection{Spectral spike detection (interactive)}
\label{\detokenize{LFP_to_bursts:spectral-spike-detection-interactive}}\label{\detokenize{LFP_to_bursts:spikes-spectral}}
Using the GUI for spectral spike detection (EdDetection:interactive:True in the parameter file) two windows will pop up.
The first window shows \(n(\theta)\), i.e. the number of spikes as a function of the spectral threshold.
The two lines indicate what the algorithm interprets as sensible thresholds. By default, \sphinxtitleref{firstcross} (the beginning
of the plateau region, corresponding to \(\theta_a\) in the \sphinxstyleemphasis{paper\_})
would be chosen, but also \sphinxtitleref{bump} (the middle of the plateau, corresponding to \(\theta_b\)) might be a good choice.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{threshdet_ntheta}.png}\hspace*{\fill}}

\begin{sphinxadmonition}{note}{\label{LFP_to_bursts:index-0}Todo:}
Link to the \sphinxstyleemphasis{paper\_}
\end{sphinxadmonition}

The second window displays the \sphinxstyleemphasis{LFP} (bottom), the \sphinxstyleemphasis{normalized spectral sum} to which the threshold is applied (middle, thresholds
shown as horizontal lines) and the \sphinxstyleemphasis{spikes detected} when applying the threshold (top).

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{threshdet_trace}.png}\hspace*{\fill}}

Zoom around in this window to see how happy you are with the performances of each of the thresholds:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{threshdet_trace_zoom}.png}\hspace*{\fill}}

And by the way, the missing values in the normalized spectral sum in this example are due to the artifact we had assigned
in this region:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{threshdet_trace_holeAtArtifact}.png}\hspace*{\fill}}

\sphinxstylestrong{Manually adding a threshold:} In case you are unhappy with the performance of \sphinxtitleref{firstcross} and \sphinxtitleref{bump}, you can add a
custom threshold yourself by a \sphinxtitleref{double right click} on \(n(\theta)\) in the first window:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{threshdet_nthetaMan}.png}\hspace*{\fill}}

In this case we added a threshold (green) between \sphinxtitleref{firstcross} and \sphinxtitleref{bump}. Upon adding a new threshold for inspection
it will also show up in the second window, so you can judge its performance:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{threshdet_trace_zoomMan}.png}\hspace*{\fill}}

\sphinxstylestrong{Picking a threshold:} For setting a threshold click the respective checkbox. Here we pick our manual threshold \sphinxtitleref{man1}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=150\sphinxpxdimen]{{threshdet_nthetaManDecision}.png}\hspace*{\fill}}

To finish the spectral spike detection, click the blue \sphinxtitleref{Done} button in the first window.

\begin{sphinxadmonition}{important}{Important:}
I highly recommend to be rather liberal with the threshold at this stage, ie. opt for a rather low threshold such as
\sphinxtitleref{firstcross} and dont worry about some false positives. False positives will later be removed through {\hyperref[\detokenize{LFP_to_bursts:spikesorting}]{\sphinxcrossref{\DUrole{std,std-ref}{Spike sorting (interactive)}}}}.
\end{sphinxadmonition}


\subsection{Spike sorting (interactive)}
\label{\detokenize{LFP_to_bursts:spike-sorting-interactive}}\label{\detokenize{LFP_to_bursts:spikesorting}}
With spike sorting we try to detect (and later remove) false positives through clustering waveforms.
If you are in interactive mode for spike sorting (SpikeSorting:interactive:True in the parameter file), two more windows
will pop up now. The panels of the first window show the clusters (waveforms of individual spikes as thin yellowish lines,
average waveforms in colors). The clusters are arranged descending from highest to lowest peak-to-peak (PTP) amplitude of the average
waveform. By default the cluster with the lowest PTP amplitude would be discharded (cluster 5 shown in red):

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{sorting_clusts}.png}\hspace*{\fill}}

The second window shows the LFP trace with spikes annotated (colored vertical lines) according to the cluster to which they were assigned.
The grey lines indicate spikes that had not been subjected to clustering because they occurred in dense \sphinxstyleemphasis{groups} and thus their waveforms
could not be separated (we do not worry too much about false positive detections in dense bursts, as they have only very minor influence
on burst classification in the end). The area shaded in yellow marks the region we excluded from analyses by assigning an {\hyperref[\detokenize{preprocessing:artifacts}]{\sphinxcrossref{\DUrole{std,std-ref}{artifact}}}}.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{sorting_trace}.png}\hspace*{\fill}}

To have a closer look at the spikes in their natural habitat, let’s zoom around in the second window:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{sorting_traceZoom1}.png}\hspace*{\fill}}

I think clusters 1 to 3 look really decent and cluster 5 clearly is a false positive. But what what about cluster 4?

\sphinxstylestrong{Marking waveforms for further inspection:} There are really few cluster 4 spikes, and it is hard to spot them in the LFP trace (second window).
So let’s mark one of those suspicious waveforms by a \sphinxtitleref{left click} in the first window. The waveform now turns cyan:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{sorting_clust_marked}.png}\hspace*{\fill}}

… and the waveform gets marked by a cyan triangle in the second window:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{sorting_trace_marked}.png}\hspace*{\fill}}

Let’s zoom in on this:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{sorting_trace_marked_zoom}.png}\hspace*{\fill}}

Oh dear, the spikes of cluster 4 appear to belong to an artifact that we did not exclude. To be super correct, we should now
{\hyperref[\detokenize{preprocessing:adding-artifacts-manually}]{\sphinxcrossref{\DUrole{std,std-ref}{edit the artifact file manually}}}}. But as this is serves for demonstration purposes only,
let’s content ourselves with annotating the spikes belonging to cluster 4 as false positives too.

\sphinxstylestrong{Picking noise clusters:} You can remove clusters as noise by checking the corresponding check boxes in the first window.
In our case, we select clusters 4 and 5 to be discarded as false positives.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{sorting_clust_selection}.png}\hspace*{\fill}}

By clicking the blue \sphinxtitleref{Done} button, we save our choice and finish this procedure.

\begin{sphinxadmonition}{note}{Note:}
If you selected \sphinxstylestrong{mixed polarity} when {\hyperref[\detokenize{preprocessing:polarity}]{\sphinxcrossref{\DUrole{std,std-ref}{assiging the polarity}}}}, you will see two rows of clusters, one for positive and one for negative polarity.
Likewise, the LFP trace will be annotated with spikes belonging to positive clusters (above the zero line) and spikes belonging to negative clusters (below
the zero line). By default the fifth cluster of both negative and positive clusters will be discarded. You can choose separately for
for positive and negative clusters which clusters to discharge as false positives.
\end{sphinxadmonition}


\section{Burst detection and classification}
\label{\detokenize{LFP_to_bursts:burst-detection-and-classification}}\label{\detokenize{LFP_to_bursts:burst-classification}}
The burst classification runs fully automatically by projecting detected spike bursts on a predefined \sphinxstyleemphasis{self-organizing map} (SOM). For the \sphinxstyleemphasis{intrahippocampal
kainate mouse model} we once calculated a \sphinxstylestrong{reference SOM} on which we project all new datasets. This worked well so far and we included the reference SOM in
the toolbox (path: \sphinxstyleemphasis{EAdetection/config/som.h5}).
If you use a different kind of animal model with different types of bursts, you might want to select other features and derive your own SOM.
To calculate the SOM itself we used the \sphinxhref{http://matias-ck.com/mlz/somz.html}{SOMz-package} by
Carrasco Kind and Brunner (“SOMz: photometric redshift PDFs with self-organizing maps and random atlas”, doi:10.1093/mnras/stt2456).
You can use a your own SOM for the projection method by setting the path to your SOM in the parameter file:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{SOM_path}.png}\hspace*{\fill}}


\chapter{Output}
\label{\detokenize{output:output}}\label{\detokenize{output:id1}}\label{\detokenize{output::doc}}
During this analysis run the following folders and files were generated:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
my\PYGZus{}results
├── data
│ └── my\PYGZus{}recording
│     ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}analysis.log
│     ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}artifacts.txt
│     ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}blipSpy.h5
│     ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}polarity.txt
│     └── my\PYGZus{}recording\PYGZus{}\PYGZus{}raw500.h5
└── figures
    └── my\PYGZus{}recording
        ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}burstClassification
        │   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}examplesOnMap\PYGZus{}thisSOM.png
        │   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}mapIds\PYGZus{}to\PYGZus{}ROIids.txt
        │   └── my\PYGZus{}recording\PYGZus{}\PYGZus{}traceClassified\PYGZus{}thisSOM.png
        ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}spikeDetection
        │   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}ampDetection.png
        │   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}detExamples.png
        │   └── my\PYGZus{}recording\PYGZus{}\PYGZus{}FofThresh.png
        └── my\PYGZus{}recording\PYGZus{}\PYGZus{}spikesorting
            ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}clusterremoval\PYGZus{}ncomp3.png
            ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}fpRemoval\PYGZus{}ex1.png
            ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}fpRemoval\PYGZus{}ex2.png
            └── my\PYGZus{}recording\PYGZus{}\PYGZus{}fpRemoval\PYGZus{}ex3.png
\end{sphinxVerbatim}

The exact location of the figure and data files depend on the location you entered when {\hyperref[\detokenize{setting_parameters:replacement-params}]{\sphinxcrossref{\DUrole{std,std-ref}{editing the parameter files}}}}
(specifically how you replaced \sphinxtitleref{DATADIR} and \sphinxtitleref{FIGDIR} in the template).


\section{Results (HDF5)}
\label{\detokenize{output:results-hdf5}}\label{\detokenize{output:resultshdf5}}
The folder \sphinxstyleemphasis{my\_results/data/my\_recording} contains the results of the analyses, most importantly \sphinxstyleemphasis{my\_recording\_\_blipSpy.h5}.
In this file all important results and intermediate steps (like the normalized averaged spectrogram) are stored.
\sphinxstyleemphasis{my\_recording\_\_blipSpy.h5} looks like this:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{hdf5Output}.png}\hspace*{\fill}}

This file contains the timings and classes of bursts (field \sphinxstyleemphasis{burstcalsses}), the train of spikes after spikesorting (\sphinxstyleemphasis{dischargedict\_cleaned}),
the train of spikes before spikesorting (i.e. the spikes resulting from spectral and amplitude based spike detection, \sphinxstyleemphasis{dischargedict\_raw})
and a link to the raw\_data contained in \sphinxstyleemphasis{my\_recording\_\_raw500.h5} (field \sphinxstyleemphasis{raw\_data/link}). Most of these fields contain three subfields
- \sphinxstyleemphasis{data}, where the actual results are stored
- \sphinxstyleemphasis{info}, where you find metadata (e.g. the version of the code used and the paths to the figures generated by these analyses)
- \sphinxstyleemphasis{methods}, giving the parameters used for a particular analysis step

You can either directly extract the data from these hdf5 files yourself (have a look at {\hyperref[\detokenize{access_results:direct-hdf5access}]{\sphinxcrossref{\DUrole{std,std-ref}{this}}}} for inspiration),
or use the {\hyperref[\detokenize{access_results:access-results}]{\sphinxcrossref{\DUrole{std,std-ref}{data handling tool}}}} we provide to conveniently access and visualize results.


\section{Quality control figures}
\label{\detokenize{output:quality-control-figures}}\label{\detokenize{output:quality-control}}
To assess whether the algorithm performed sensibly, figures were created and saved in the folder \sphinxstyleemphasis{my\_results/data/my\_recording}.
You can turn this off in the parameter file (\sphinxtitleref{analysis:save\_figs: False}) …

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=350\sphinxpxdimen]{{params_savefigs}.png}\hspace*{\fill}}

… but I highly recommend you keep saving these figures and routinely check them to see whether everything works well.
In the following you will learn how to interpret these figures.


\subsection{Spike detection}
\label{\detokenize{output:spike-detection}}
The folder \sphinxstylestrong{my\_recording\_\_spikeDetection} contains three figure files:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
my\PYGZus{}recording\PYGZus{}\PYGZus{}spikeDetection
 ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}ampDetection.png
 ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}detExamples.png
 └── my\PYGZus{}recording\PYGZus{}\PYGZus{}FofThresh.png
\end{sphinxVerbatim}

The figure \sphinxstyleemphasis{my\_recording\_\_FofThresh.png} displays the number of spikes as a function of threshold (\(n(\theta)\), see also {\hyperref[\detokenize{LFP_to_bursts:spikes-spectral}]{\sphinxcrossref{\DUrole{std,std-ref}{spectral spike detection}}}}).
The circle indicates the threshold selected. As we manually picked the threshold in this example, the \sphinxtitleref{mode} is \sphinxtitleref{man}.
The green line displays the derivative of \(n(\theta)\) based on which the plateau region was determined:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{my_recording__FofThresh}.png}\hspace*{\fill}}

For a proper spike detection we need a plateau region (\sphinxstyleemphasis{paper\_Figure XXX\_}), that is a region where \(n(\theta)\) increases only very slowly.
Non-epileptic mice lack such a pleateau. Here we are content, because a plateau is clearly visible and the threshold is located
nicely within the plateau region.

The figure \sphinxstyleemphasis{my\_recording\_\_ampDetection.png} displays the amplitude distribution of the LFP with spectral spikes masked (black) and
spectral + amplitude spikes masked (green, \sphinxstyleemphasis{paper\_Figure XXX\_}). The red line indicates the value where
the amplitude threshold was automatically set (-4.5 due to negative {\hyperref[\detokenize{preprocessing:polarity}]{\sphinxcrossref{\DUrole{std,std-ref}{polarity}}}}) and the red numbers in the upper right
corner state again the threshold, the absolute number of amplitude spikes \#(amp-EDs), and how the number of spikes increased
through amplitude based spike detection:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=350\sphinxpxdimen]{{my_recording__ampDetection}.png}\hspace*{\fill}}

In this case the shoulder for negative values is very small (note the logarithmic y-axis) and consequently very few spikes
were detected as amplitude spikes (0.9\% increase only).

The figure \sphinxstyleemphasis{my\_recording\_\_detExamples.png} shows five randomly selected 40s snippets of LFP with spectal and amplitude spikes
annotated by blue and red ticks respectively. Regions {\hyperref[\detokenize{preprocessing:artifacts}]{\sphinxcrossref{\DUrole{std,std-ref}{annotated as artifacts}}}} are shaded in yellow.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{my_recording__detExamples}.png}\hspace*{\fill}}

Because there were so few amplitude spikes (i.e. spectral spike detection did a good job), we dont see any red ticks here.
But we notice some false positives, eg. in the first and second row. Luckily these were probably removed by
{\hyperref[\detokenize{LFP_to_bursts:spikesorting}]{\sphinxcrossref{\DUrole{std,std-ref}{spike sorting}}}}.


\subsection{Spike sorting}
\label{\detokenize{output:spike-sorting}}
The folder \sphinxstylestrong{my\_recording\_\_spikesorting} contains one file again displaying the spike clusters and three figures
of LFP traces annoted with putative false positives detected through spike sorting:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
my\PYGZus{}recording\PYGZus{}\PYGZus{}spikesorting
   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}clusterremoval\PYGZus{}ncomp3.png
   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}fpRemoval\PYGZus{}ex1.png
   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}fpRemoval\PYGZus{}ex2.png
   └── my\PYGZus{}recording\PYGZus{}\PYGZus{}fpRemoval\PYGZus{}ex3.png
\end{sphinxVerbatim}

The figure \sphinxstyleemphasis{my\_recording\_\_clusterremoval\_ncomp3.png} (ncomp3 refers to the default of three principal components used for sorting)
have already seen when running {\hyperref[\detokenize{LFP_to_bursts:spikesorting}]{\sphinxcrossref{\DUrole{std,std-ref}{spike sorting in interactive mode}}}}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{my_recording__clusterremoval_ncomp3}.png}\hspace*{\fill}}

If you ran everything automatically (by default only cluster 5 is removed) you would get suspicious and now run the
sorting again to remove cluster 4 as well.
But as indicated by the \sphinxtitleref{checkmarks}, we already removed cluster 4 as well and are very content, because clusters
1-3 show nice spike-like waveforms, while clusters 4 and 5 do not look like spikes.

The figures \sphinxstyleemphasis{my\_recording\_\_fpRemoval\_ex1-3.png} show five randomly selected 20s snippets of LFP with non-removed (\sphinxstyleemphasis{accepted EDs}, blue)
and false positives detected through spike sorting (red) indicated by tickmarks. The grey regions indicates the waveform
cutouts subjected to spike sorting.
Regions {\hyperref[\detokenize{preprocessing:artifacts}]{\sphinxcrossref{\DUrole{std,std-ref}{annotated as artifacts}}}} are shaded in yellow.
Here is one of these example figures:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{my_recording__fpRemoval_ex3}.png}\hspace*{\fill}}

Note that spikes occuring in groups were not subjected to spike sorting (last row). Overall, we are very happy
with the performance, most false positives appear to have been detected. If you noticed an awful lot of false positives
in these example figures, you might need to {\hyperref[\detokenize{LFP_to_bursts:spikes-spectral}]{\sphinxcrossref{\DUrole{std,std-ref}{change the threshold for spectral spike detection}}}}
or {\hyperref[\detokenize{LFP_to_bursts:spikesorting}]{\sphinxcrossref{\DUrole{std,std-ref}{exclude more/different clusters}}}}. Likewise, if you observed too many false negatives or spikes being wrong-
fully labeled false positives here.


\subsection{Burst classification}
\label{\detokenize{output:burst-classification}}
The folder \sphinxstylestrong{my\_recording\_\_burstClassification} contains two figures related to burst classification:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
my\PYGZus{}recording\PYGZus{}\PYGZus{}burstClassification
   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}examplesOnMap\PYGZus{}thisSOM.png
   ├── my\PYGZus{}recording\PYGZus{}\PYGZus{}mapIds\PYGZus{}to\PYGZus{}ROIids.txt
   └── my\PYGZus{}recording\PYGZus{}\PYGZus{}traceClassified\PYGZus{}thisSOM.png
\end{sphinxVerbatim}

The figure \sphinxstyleemphasis{my\_recording\_\_examplesOnMap\_thisSOM.png} displays the SOM (left) and how spikes bursts (randomly chosen)
were assigned to nodes of the SOM (right). The colors indicate the different burst classes. Note that the high-load
cluster is sub-differentiated here in \sphinxtitleref{high-load 1} (red) and \sphinxtitleref{high-load 2} (orange).:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{my_recording__examplesOnMap_thisSOM}.png}\hspace*{\fill}}

The file \sphinxstyleemphasis{my\_recording\_\_mapIds\_to\_ROIids.txt} translates the burst ids given in this figure to the actual burst ids in the
data (in case you want to hunt down a particular burst). Everything looks nice, bursts appear to be assigned properly
and according to our intuition of severity. Pay special heed to this figure when applying our algorithm to a different
mouse model. If things look strange here, you {\hyperref[\detokenize{LFP_to_bursts:burst-classification}]{\sphinxcrossref{\DUrole{std,std-ref}{may need to use different kinds of features and/or build your
own SOM}}}}.

The figure \sphinxstyleemphasis{my\_recording\_\_traceClassified\_thisSOM.png} shows the whole trace of the LFP with the burst classes (colors) and
solitary spikes (black tickmarks) displayed on top. The purpose of this figure is to give you an overview of the sequence of
classified EA events. Note that here the EA is classified in t-shirt sizes to allow for a more detailed classification.
The category \sphinxtitleref{low-load} in the \sphinxstyleemphasis{paper\_} comprises all \sphinxtitleref{XS} (bursts with fewer than five spikes which were not classified
on the SOM) and \sphinxtitleref{S} (low-load bursts classified through the SOM) bursts shown here. The \sphinxtitleref{medium-load} bursts are category
\sphinxtitleref{M} and the category \sphinxtitleref{high-load} comprises all \sphinxtitleref{L} (={}`high-load2{}`) and \sphinxtitleref{XL} (={}`high-load1{}`) bursts:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=750\sphinxpxdimen]{{my_recording__traceClassified_thisSOM}.png}\hspace*{\fill}}

\begin{sphinxadmonition}{note}{\label{output:index-0}Todo:}
Links for \sphinxstyleemphasis{paper\_Figure XXX\_} and \sphinxstyleemphasis{paper\_}, in the whole section
\end{sphinxadmonition}


\chapter{Accessing results}
\label{\detokenize{access_results:accessing-results}}\label{\detokenize{access_results:access-results}}\label{\detokenize{access_results::doc}}
Here is how to use the modules and scripts that allow you to conveniently access and visualize the results stored
during analyses in the {\hyperref[\detokenize{output:resultshdf5}]{\sphinxcrossref{\DUrole{std,std-ref}{main output hdf5-file}}}}. We provide access tools for both {\hyperref[\detokenize{access_results:python-access}]{\sphinxcrossref{\DUrole{std,std-ref}{Python}}}} and
{\hyperref[\detokenize{access_results:matlab-access}]{\sphinxcrossref{\DUrole{std,std-ref}{Matlab}}}}, but note that the access through Python provides more advanced features.


\section{Python}
\label{\detokenize{access_results:python}}\label{\detokenize{access_results:python-access}}

\subsection{Setting things up}
\label{\detokenize{access_results:setting-things-up}}
Make sure that you are in the virtual environment for EAdetection (in case you decided to use one):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{workon} \PYG{n}{EAdetectionEnv}
\end{sphinxVerbatim}

For me, the command line now looks like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(EAdetectionEnv) weltgeischt@weltgeischt:\PYGZti{}/EAdetection\PYGZus{}tutorial\PYGZdl{}
\end{sphinxVerbatim}

Navigate into the directory of EAdetection:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{cd} \PYG{n}{EAdetection}
\end{sphinxVerbatim}

I am now in (pwd for showing the current directory):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{pwd}
\PYG{o}{/}\PYG{n}{home}\PYG{o}{/}\PYG{n}{weltgeischt}\PYG{o}{/}\PYG{n}{EAdetection\PYGZus{}tutorial}\PYG{o}{/}\PYG{n}{EAdetection}
\end{sphinxVerbatim}

Start python or ipython:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{ipython}
\end{sphinxVerbatim}

From within python, we first import some useful modules:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [1]: }\PYG{k+kn}{import} \PYG{n+nn}{core.ea\PYGZus{}management} \PYG{k+kn}{as} \PYG{n+nn}{eam}
\PYG{g+gp}{In [2]: }\PYG{k+kn}{import} \PYG{n+nn}{core.helpers} \PYG{k+kn}{as} \PYG{n+nn}{hf}
\PYG{g+gp}{In [3]: }\PYG{k+kn}{import} \PYG{n+nn}{matplotlib.pyplot} \PYG{k+kn}{as} \PYG{n+nn}{plt}
\PYG{g+gp}{In [4]: }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\end{sphinxVerbatim}


\subsection{Initialize recording object}
\label{\detokenize{access_results:initialize-recording-object}}
There are two ways to initialize a recording object and thereby gain access to the data. First,
you can initialize a recording object with its parameter file.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [2]: }\PYG{n}{paramfile} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/weltgeischt/EAdetection\PYGZus{}tutorial/run\PYGZus{}params/my\PYGZus{}recording\PYGZus{}params.yml}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{g+gp}{In [6]: }\PYG{n}{aRec} \PYG{o}{=} \PYG{n}{eam}\PYG{o}{.}\PYG{n}{Rec}\PYG{p}{(}\PYG{n}{init\PYGZus{}ymlpath}\PYG{o}{=}\PYG{n}{paramfile}\PYG{p}{)}
\end{sphinxVerbatim}

Alternatively, you could initialize it directly with the {\hyperref[\detokenize{output:resultshdf5}]{\sphinxcrossref{\DUrole{std,std-ref}{results file}}}} results file.
If you want to plot colorful bursts, this option also requires you to give the path to the SOM.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [3]: }\PYG{n}{datapath} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/weltgeischt/EAdetection\PYGZus{}tutorial/my\PYGZus{}results/data/my\PYGZus{}recording/my\PYGZus{}recording\PYGZus{}\PYGZus{}blipSpy.h5}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{g+gp}{In [8]: }\PYG{n}{sompath} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/weltgeischt/EAdetection\PYGZus{}tutorial/EAdetection/config/som.h5}\PYG{l+s+s1}{\PYGZsq{}}
\PYG{g+gp}{In [9]: }\PYG{n}{aRec} \PYG{o}{=} \PYG{n}{eam}\PYG{o}{.}\PYG{n}{Rec}\PYG{p}{(}\PYG{n}{init\PYGZus{}datapath}\PYG{o}{=}\PYG{n}{datapath}\PYG{p}{,}\PYG{n}{sompath}\PYG{o}{=}\PYG{n}{sompath}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
If you dislike objects and want to extract the data directly from the hdf5 file, you are
allowed to {\hyperref[\detokenize{access_results:direct-hdf5access}]{\sphinxcrossref{\DUrole{std,std-ref}{skip ahead}}}}.
\end{sphinxadmonition}


\subsection{Visualize EA sequences}
\label{\detokenize{access_results:visualize-ea-sequences}}
Now let’s plot the LFP and the EA we detected:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [4]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{raw}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{artifacts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{spikes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{singlets}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bursts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{legendOn}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{g+gp}{In [11]: }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

In the resulting plot you see the LFP trace (bottom), all spikes detected (middle, red ticks), and the sequence
of bursts (top colored according to category) and solitary spikes (black ticks). The part of the LFP that we
annotated as artifact was disregarded for analyses and is shown in a yellow shade:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{access_tshirt}.png}\hspace*{\fill}}

In this representation you see t-shirt size categorization which allow for a finer distinction that
the one given in the \sphinxstyleemphasis{paper\_}. \sphinxtitleref{XS} and \sphinxtitleref{S} bursts correspond to \sphinxtitleref{low-load} bursts, \sphinxtitleref{M} bursts are \sphinxtitleref{medium-load} bursts,
and \sphinxtitleref{XL} and \sphinxtitleref{L} bursts correspond to \sphinxtitleref{high-load} bursts. In this representation bursts with a spike load index = 1
(\sphinxtitleref{LI1}) are marked in purple (technically these are also \sphinxtitleref{XL} bursts).

\begin{sphinxadmonition}{note}{\label{access_results:index-0}Todo:}
\sphinxstyleemphasis{paper\_} link
\end{sphinxadmonition}

If you prefer the more compact, \sphinxstylestrong{load-based categorizations} (as in the papers) you can switch the naming scheme
and coloring by executing:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [5]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{loadify\PYGZus{}bursts}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

As you can see when plotting now, colors and cluster identity are now given in the load scheme:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [6]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{raw}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{artifacts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{spikes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{singlets}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bursts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,}\PYG{n}{legendOn}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,}\PYG{n}{loadlegend}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{g+gp}{In [14]: }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{access_loadplot}.png}\hspace*{\fill}}


\subsection{Accessing the results (examples)}
\label{\detokenize{access_results:accessing-the-results-examples}}
The recording object provides a convenient access to everything that was analyzed:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [7]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{dur}\PYG{c+c1}{\PYGZsh{} duration of whole recording}
\PYG{g+gh}{Out[7]: }\PYG{g+go}{4784.398}

\PYG{g+gp}{In [8]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{offset} \PYG{c+c1}{\PYGZsh{}the time we excluded at the beginning ot the recording}
\PYG{g+gh}{Out[8]: }\PYG{g+go}{300}

\PYG{g+gp}{In [9]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{artifactTimes} \PYG{c+c1}{\PYGZsh{}start and stop times of annoted artifacts}
\PYG{g+gh}{Out[9]: }
\PYG{g+go}{array([[2978.61, 3348.16],}
\PYG{g+go}{       [4153.07, 4157.07]])}

\PYG{g+gp}{In [10]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{durAnalyzed}\PYG{c+c1}{\PYGZsh{} duration \PYGZhy{} offset \PYGZhy{} artifact times}
\PYG{g+gh}{Out[10]: }\PYG{g+go}{4110.848}
\end{sphinxVerbatim}

You can directy extract the \sphinxstylestrong{spiketimes} and e.g. calculate the overall \sphinxstylestrong{spike rate} from it:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [11]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{spiketimes} \PYG{c+c1}{\PYGZsh{}timepoints of spikes detected}
\PYG{g+gh}{Out[11]: }\PYG{g+go}{array([ 350.472,  352.368,  353.184, ..., 4783.702, 4784.058, 4784.198])}

\PYG{g+gp}{In [12]: }\PYG{n}{spikerate} \PYG{o}{=} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{spiketimes}\PYG{p}{)}\PYG{o}{/}\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{durAnalyzed}

\PYG{g+gp}{In [13]: }\PYG{k}{print} \PYG{p}{(}\PYG{n}{spikerate}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{spikes/second}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+go}{0.4208377444264541 spikes/second}
\end{sphinxVerbatim}

Our recording object contains a list of burst objects, that is the bursts that happend during the recording:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [14]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{bursts} \PYG{c+c1}{\PYGZsh{}list of burst objects}
\PYG{g+gh}{Out[14]: }
\PYG{g+go}{[\PYGZlt{}core.ea\PYGZus{}management.Burst at 0x7f79bd806c88\PYGZgt{},}
\PYG{g+go}{ \PYGZlt{}core.ea\PYGZus{}management.Burst at 0x7f79b7cd2e48\PYGZgt{},}
\PYG{g+go}{ \PYGZlt{}core.ea\PYGZus{}management.Burst at 0x7f79b7cd2b70\PYGZgt{},}
\PYG{g+go}{    .......................................}
\PYG{g+go}{ \PYGZlt{}core.ea\PYGZus{}management.Burst at 0x7f79b7cf16d8\PYGZgt{}]}
\end{sphinxVerbatim}

Each \sphinxstylestrong{burst object} has a start and stop point in time (\sphinxtitleref{.start},{}`.stop{}`), a duration (\sphinxtitleref{.dur}), a category (\sphinxtitleref{.cname}),
a color (\sphinxtitleref{.color}, useful for plotting), a listing of its constituent spikes (\sphinxtitleref{.spiketimes}), a spike load index
(\sphinxtitleref{.si}) and a few other properties.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [15]: }\PYG{n}{B} \PYG{o}{=} \PYG{n}{aRec}\PYG{o}{.}\PYG{n}{bursts}\PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{c+c1}{\PYGZsh{} for example lets pick burst number 10 and name it}

\PYG{g+gp}{In [16]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{start}
\PYG{g+gh}{Out[16]: }\PYG{g+go}{919.578}

\PYG{g+gp}{In [17]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{stop}
\PYG{g+gh}{Out[17]: }\PYG{g+go}{923.682}

\PYG{g+gp}{In [18]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{roi} \PYG{c+c1}{\PYGZsh{}start and stop time}
\PYG{g+gh}{Out[18]: }\PYG{g+go}{[919.578, 923.682]}

\PYG{g+gp}{In [19]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{dur}
\PYG{g+gh}{Out[19]: }\PYG{g+go}{4.104000000000042}

\PYG{g+gp}{In [20]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{cname}
\PYG{g+gh}{Out[20]: }\PYG{g+go}{\PYGZsq{}low\PYGZhy{}load\PYGZsq{}}

\PYG{g+gp}{In [21]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{color}
\PYG{g+gh}{Out[21]: }\PYG{g+go}{\PYGZsq{}\PYGZsh{}4476bd\PYGZsq{}}

\PYG{g+gp}{In [22]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{spiketimes}
\PYG{g+gh}{Out[22]: }\PYG{g+go}{array([919.578, 921.264, 923.258, 923.682])}

\PYG{g+gp}{In [23]: }\PYG{n}{B}\PYG{o}{.}\PYG{n}{si} \PYG{c+c1}{\PYGZsh{}None because not classified on the SOM (\PYGZlt{}5 spikes), so lets pick a different example ...}

\PYG{g+gp}{In [24]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{bursts}\PYG{p}{[}\PYG{l+m+mi}{33}\PYG{p}{]}\PYG{o}{.}\PYG{n}{si}
\PYG{g+gh}{Out[24]: }\PYG{g+go}{0.17557326391422834}
\end{sphinxVerbatim}

You can \sphinxstylestrong{collect burst objects} of a certain type and perform computations on them.
Let’s e.g. collect high-load bursts and calculate their rate:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [25]: }\PYG{n}{hl\PYGZus{}bursts} \PYG{o}{=} \PYG{p}{[}\PYG{n}{B} \PYG{k}{for} \PYG{n}{B} \PYG{o+ow}{in} \PYG{n}{aRec}\PYG{o}{.}\PYG{n}{bursts} \PYG{k}{if} \PYG{n}{B}\PYG{o}{.}\PYG{n}{cname}\PYG{o}{==}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{high\PYGZhy{}load}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{}list of burst objects}
\PYG{g+gp}{In [34]: }\PYG{n}{N\PYGZus{}hl} \PYG{o}{=} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{hl\PYGZus{}bursts}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}number of high\PYGZhy{}load bursts}
\PYG{g+gp}{In [35]: }\PYG{n}{rate\PYGZus{}hl} \PYG{o}{=} \PYG{n}{N\PYGZus{}hl}\PYG{o}{/}\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{durAnalyzed}
\PYG{g+gp}{In [36]: }\PYG{k}{print} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{High\PYGZhy{}load rate (/min): }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{rate\PYGZus{}hl}\PYG{o}{*}\PYG{l+m+mf}{60.}\PYG{p}{)}\PYG{c+c1}{\PYGZsh{}*60 to get /min}
\PYG{g+go}{High\PYGZhy{}load rate (/min):  0.2919105741686387}
\end{sphinxVerbatim}

Similarly we can also calculate the absolute \sphinxstylestrong{time spent in high-load bursts} and the fraction of time
spent in high-load bursts:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [26]: }\PYG{n}{dur\PYGZus{}hl} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{p}{[}\PYG{n}{B}\PYG{o}{.}\PYG{n}{dur} \PYG{k}{for} \PYG{n}{B} \PYG{o+ow}{in} \PYG{n}{hl\PYGZus{}bursts}\PYG{p}{]}\PYG{p}{)}

\PYG{g+gp}{In [27]: }\PYG{k}{print} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Total hl\PYGZhy{}duration (min): }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dur\PYGZus{}hl}\PYG{o}{/}\PYG{l+m+mf}{60.}\PYG{p}{)}\PYG{c+c1}{\PYGZsh{}/ 60 to get min}
\PYG{g+go}{Total hl\PYGZhy{}duration (min):  5.909600000000008}

\PYG{g+gp}{In [28]: }\PYG{k}{print} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Relative time in high\PYGZhy{}loads: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{dur\PYGZus{}hl}\PYG{o}{/}\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{durAnalyzed}\PYG{p}{)}\PYG{c+c1}{\PYGZsh{}/ 60 to get min}
\PYG{g+go}{Relative time in high\PYGZhy{}loads:  0.08625373645534948}
\end{sphinxVerbatim}

You can also address \sphinxstylestrong{EA-free snippets} as objects, in a way very similar to bursts:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [29]: }\PYG{n}{aRec}\PYG{o}{.}\PYG{n}{freesnips} \PYG{c+c1}{\PYGZsh{}list of EA\PYGZhy{}free snippet objects in the recording}
\PYG{g+gh}{Out[29]: }
\PYG{g+go}{[\PYGZlt{}core.ea\PYGZus{}management.Period at 0x7f79b410cda0\PYGZgt{},}
\PYG{g+go}{ \PYGZlt{}core.ea\PYGZus{}management.Period at 0x7f79b410cdd8\PYGZgt{},}
\PYG{g+go}{ \PYGZlt{}core.ea\PYGZus{}management.Period at 0x7f79b410ccc0\PYGZgt{},}
\PYG{g+go}{    .......................................}
\PYG{g+go}{ \PYGZlt{}core.ea\PYGZus{}management.Period at 0x7f79b4114c18\PYGZgt{}]}

\PYG{g+gp}{In [30]: }\PYG{n}{aFree} \PYG{o}{=} \PYG{n}{aRec}\PYG{o}{.}\PYG{n}{freesnips}\PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{}10th EA\PYGZhy{}free snippet}

\PYG{g+gp}{In [31]: }\PYG{n}{aFree}\PYG{o}{.}\PYG{n}{roi} \PYG{c+c1}{\PYGZsh{}start and stop time}
\PYG{g+gh}{Out[31]: }\PYG{g+go}{[586.5360000000001, 593.752]}

\PYG{g+gp}{In [32]: }\PYG{n}{aFree}\PYG{o}{.}\PYG{n}{dur} \PYG{c+c1}{\PYGZsh{}duration}
\PYG{g+gh}{Out[32]: }\PYG{g+go}{7.2159999999998945}
\end{sphinxVerbatim}

If you want to concentrate your analysis on a particular \sphinxstylestrong{cutout} of data you can do so too.
The cutout can then be analysed and visualized in the same way as a the whole recording

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [33]: }\PYG{n}{cutRec} \PYG{o}{=} \PYG{n}{eam}\PYG{o}{.}\PYG{n}{EAPeriod}\PYG{p}{(}\PYG{l+m+mf}{3630.}\PYG{p}{,}\PYG{l+m+mf}{3900.}\PYG{p}{,}\PYG{n}{parentobj}\PYG{o}{=}\PYG{n}{aRec}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}cut out from recording object}

\PYG{g+gp}{In [34]: }\PYG{n}{cutRec}\PYG{o}{.}\PYG{n}{bursts}\PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{o}{.}\PYG{n}{dur} \PYG{c+c1}{\PYGZsh{}duration of the 10th burst in the cutout}
\PYG{g+gh}{Out[34]: }\PYG{g+go}{0.43039182282791444}

\PYG{g+gp}{In [35]: }\PYG{k}{print} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cutout spikerate: }\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{cutRec}\PYG{o}{.}\PYG{n}{spiketimes}\PYG{p}{)}\PYG{o}{/}\PYG{n}{cutRec}\PYG{o}{.}\PYG{n}{dur}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{spikes/second}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{g+go}{Cutout spikerate:  1.1814814814814816 spikes/second}

\PYG{g+gp}{In [36]: }\PYG{n}{cutRec}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{raw}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{artifacts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{spikes}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{singlets}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{bursts}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}plot cutout}
\PYG{g+gp}{In [48]: }\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{access_cutout}.png}\hspace*{\fill}}


\subsection{Directly extract data from hdf5}
\label{\detokenize{access_results:directly-extract-data-from-hdf5}}\label{\detokenize{access_results:direct-hdf5access}}
You can also directly extract the data directly from the {\hyperref[\detokenize{output:resultshdf5}]{\sphinxcrossref{\DUrole{std,std-ref}{main results file}}}}.
If you want to operate with data-arrays directly this might be a more efficient solution.
In the following, \sphinxtitleref{datapath} refers to the path of the main results file.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{In [37]: }\PYG{n}{datapath} \PYG{o}{=} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{/home/weltgeischt/EAdetection\PYGZus{}tutorial/my\PYGZus{}results/data/my\PYGZus{}recording/my\PYGZus{}recording\PYGZus{}\PYGZus{}blipSpy.h5}\PYG{l+s+s1}{\PYGZsq{}}

\PYG{g+gp}{In [38]: }\PYG{n}{results} \PYG{o}{=} \PYG{n}{hf}\PYG{o}{.}\PYG{n}{open\PYGZus{}hdf5}\PYG{p}{(}\PYG{n}{datapath}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{}this opens the main results file}

\PYG{g+gp}{In [39]: }\PYG{k}{print} \PYG{p}{(}\PYG{n}{results}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} gives you the sub\PYGZhy{}fields of the resultsfile}
\PYG{g+go}{dict\PYGZus{}keys([\PYGZsq{}burstclasses\PYGZsq{}, \PYGZsq{}dischargedict\PYGZus{}cleaned\PYGZsq{}, \PYGZsq{}dischargedict\PYGZus{}raw\PYGZsq{}, \PYGZsq{}raw\PYGZus{}data\PYGZsq{}])}

\PYG{g+gp}{In [40]: }\PYG{n}{burstdata} \PYG{o}{=} \PYG{n}{results}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{burstclasses}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}

\PYG{g+gp}{In [41]: }\PYG{k}{print} \PYG{p}{(}\PYG{n}{burstdata}\PYG{o}{.}\PYG{n}{keys}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} whats in the burst data?}
\PYG{g+go}{dict\PYGZus{}keys([\PYGZsq{}params\PYGZsq{}, \PYGZsq{}values\PYGZsq{}])}

\PYG{g+gp}{In [42]: }\PYG{n}{burstdata}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{params}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{}these are whats in the \PYGZsq{}values\PYGZsq{}}
\PYG{g+gh}{Out[42]: }\PYG{g+go}{[\PYGZsq{}key\PYGZus{}id\PYGZsq{}, \PYGZsq{}start\PYGZsq{}, \PYGZsq{}stop\PYGZsq{}, \PYGZsq{}clustid\PYGZsq{}, \PYGZsq{}seizidx\PYGZsq{}, \PYGZsq{}bmu\PYGZsq{}]}

\PYG{g+gp}{In [43]: }\PYG{n}{burstdata}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{shape} \PYG{c+c1}{\PYGZsh{} (number of bursts) x (number of parameters)}
\PYG{g+gh}{Out[43]: }\PYG{g+go}{(125, 6)}

\PYG{g+gp}{In [44]: }\PYG{n}{starttimes} \PYG{o}{=} \PYG{n}{burstdata}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{values}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{n}{burstdata}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{params}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{index}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{start}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]} \PYG{c+c1}{\PYGZsh{} starttimes of all bursts}

\PYG{g+gp}{In [45]: }\PYG{n}{starttimes}
\PYG{g+gh}{Out[45]: }
\PYG{g+go}{array([ 445.338     ,  846.258     ,  860.334     , 1031.31      ,}
\PYG{g+go}{       1081.86      , 1467.002     , 1500.36      , 1509.08      ,}
\PYG{g+go}{        ....................................................}
\PYG{g+go}{       4346.366     , 4454.184     , 4617.296     , 4710.278     ,}
\PYG{g+go}{       4759.026     ])}
\end{sphinxVerbatim}

As you have seen, you can get out a lot from the data. Happy hacking and exploring!


\section{Matlab}
\label{\detokenize{access_results:matlab}}\label{\detokenize{access_results:matlab-access}}
Accessing the results in matlab is very similar to accessing them in python (e.g. \sphinxtitleref{aRec.spiketimes} for getting the spiketrain, see
{\hyperref[\detokenize{access_results:python-access}]{\sphinxcrossref{\DUrole{std,std-ref}{previous section}}}}).
Have a look at the example in \sphinxstyleemphasis{EAdetection/examples/matlab/use\_matlab.m}. As some of the fancier features (e.g. plotting)
are not developed yet, you are very welcome to expand the reader for matlab access at \sphinxstyleemphasis{EAdetection/examples/matlab/READEA.m}.


\chapter{Accessing metadata and diagnostics metrics}
\label{\detokenize{access_metadata:accessing-metadata-and-diagnostics-metrics}}\label{\detokenize{access_metadata:access-metadata}}\label{\detokenize{access_metadata::doc}}
You can render metadata and diagnostics metrics automatically in human readable form using odML or yaml. A single metadata
and/or diagnostics file is created for a specific recording.

\sphinxstylestrong{Metadata} includes the parameters used for analyses and details about who analyzed the data when and the paths to the
figures created during the different analysis steps. Therefore metadata is sub-section into the fields:
\begin{itemize}
\item {} 
\sphinxtitleref{EdDetection}, for spectral and ampltiude based spike detection

\item {} 
\sphinxtitleref{SpikeSorting}, for sorting of spikes to remove false positives

\item {} 
\sphinxtitleref{BurstClassification}, for burst detection and classification

\end{itemize}

\sphinxstylestrong{Diagnostics metrics} include metrics we commonly use to address the severity of epilepsy. These include:
\begin{itemize}
\item {} 
\sphinxtitleref{rate(spikes)}, the rate of spikes detected during the recording (/s)

\item {} 
\sphinxtitleref{rate(high-load)}, the rate of high-load bursts (/min)

\item {} 
\sphinxtitleref{tfrac(high-load)}, the fraction of time spent in high-load bursts

\item {} 
\sphinxtitleref{tfrac(bursts)}, the fraction of time spent in bursts of any kind

\item {} 
\sphinxtitleref{tfrac(free)}, the fraction of time spent outside of bursts

\item {} 
\sphinxtitleref{burstiness}, (std(ISI)-mean(ISI))/(std(ISI)+mean(ISI)); ISI being interspike interval, see Goh and Barabási (2008)

\end{itemize}


\section{General}
\label{\detokenize{access_metadata:general}}
Before you start, make sure that you are in the virtual environment for EAdetection if you have {\hyperref[\detokenize{getting_started:virtual-env}]{\sphinxcrossref{\DUrole{std,std-ref}{set up one}}}}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{workon} \PYG{n}{EAdetectionEnv}
\end{sphinxVerbatim}

… and make sure you are in the folder of EAdetection. My command-line would look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
(EAdetectionEnv) weltgeischt@weltgeischt:\PYGZti{}/EAdetection\PYGZus{}tutorial/EAdetection\PYGZdl{}
\end{sphinxVerbatim}

The general \sphinxstylestrong{command structure} for rendering metadata and diagnostics in both formats looks like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{metadata\PYGZus{}diagnostics}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{o}{\PYGZlt{}}\PYG{n+nb}{format}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZlt{}}\PYG{n}{options}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{path}\PYG{o}{/}\PYG{n}{to}\PYG{o}{/}\PYG{n}{paramfile}\PYG{o}{.}\PYG{n}{yml}\PYG{o}{\PYGZgt{}}
\end{sphinxVerbatim}

\sphinxtitleref{\textless{}format\textgreater{}} can be either \sphinxtitleref{yaml} or \sphinxtitleref{odml}, depending on your taste of filetype

\sphinxtitleref{\textless{}options\textgreater{}} can be:
\begin{itemize}
\item {} 
\sphinxtitleref{d} for rendering diagnostic metrics

\item {} 
\sphinxtitleref{m} for rendering metadata metrics

\item {} 
\sphinxtitleref{md} for rendering metadata and disagnostic metrics in a single file

\end{itemize}


\section{odML}
\label{\detokenize{access_metadata:odml}}\label{\detokenize{access_metadata:metaodml}}
If you want to know more about odML, have a look at \sphinxhref{https://github.com/G-Node/python-odml/blob/master/doc/tutorial.rst}{this}.
To be able to render something in odML format, you need to have odml installed. You can do so using pip:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{pip3} \PYG{n}{install} \PYG{n}{odml}
\end{sphinxVerbatim}


\subsection{Example 1}
\label{\detokenize{access_metadata:example-1}}\label{\detokenize{access_metadata:example1-meta}}
Now, lets render \sphinxstylestrong{diagnostic metrics} of our example recording in \sphinxstylestrong{odML format}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{metadata\PYGZus{}diagnostics}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{n}{odml} \PYG{o}{\PYGZhy{}}\PYG{n}{d} \PYG{o}{/}\PYG{n}{home}\PYG{o}{/}\PYG{n}{weltgeischt}\PYG{o}{/}\PYG{n}{EAdetection\PYGZus{}tutorial}\PYG{o}{/}\PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

This generates a file \sphinxstyleemphasis{my\_recording\_\_diagnostics.xml}  at {\hyperref[\detokenize{setting_parameters:replacement-params}]{\sphinxcrossref{\DUrole{std,std-ref}{the folder we had assigned to store the data}}}},
in my case \sphinxstyleemphasis{/home/weltgeischt/EAdetection\_tutorial/my\_results/data/my\_recording}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=300\sphinxpxdimen]{{md_diagnostics_odml_folder}.png}\hspace*{\fill}}

Open the file in your browser (e.g. right click on the file and select \sphinxtitleref{Open With \textgreater{} Firefox}). It should look like this:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{md_diagnostics_odml1}.png}\hspace*{\fill}}

If you now click at the blue \sphinxtitleref{Diagnostics} tab, it will bring you to all the beautiful diagnostic metrics:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{md_diagnostics_odml2}.png}\hspace*{\fill}}


\subsection{Example 2}
\label{\detokenize{access_metadata:example-2}}\label{\detokenize{access_metadata:example2-meta}}
Now let’s render \sphinxstylestrong{metadata} in \sphinxstylestrong{odML format}. You type the same as in {\hyperref[\detokenize{access_metadata:example1-meta}]{\sphinxcrossref{\DUrole{std,std-ref}{the previous example}}}},
only that you now use option \sphinxtitleref{-m} instead of \sphinxtitleref{-d}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{metadata\PYGZus{}diagnostics}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{n}{odml} \PYG{o}{\PYGZhy{}}\PYG{n}{m} \PYG{o}{/}\PYG{n}{home}\PYG{o}{/}\PYG{n}{weltgeischt}\PYG{o}{/}\PYG{n}{EAdetection\PYGZus{}tutorial}\PYG{o}{/}\PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

This generates a file \sphinxstyleemphasis{my\_recording\_\_metadata.xml} in the results folder. Open it in your browser. As you see it displays a
section for each analysis step, with subsection called \sphinxtitleref{…\_methods} and \sphinxtitleref{…\_info}. In the former you find the parameters
used for running the analyses, in the latter you have links to figures generated and who ran the procedure when. Clicking
on the respective subsection will directly bring you to its content.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{md_metadata_odml}.png}\hspace*{\fill}}


\subsection{Example 3}
\label{\detokenize{access_metadata:example-3}}
To produce a single file that contains both \sphinxstylestrong{metadata and diagnostic metrics} in \sphinxstylestrong{odML format}, use option \sphinxtitleref{-md}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{metadata\PYGZus{}diagnostics}\PYG{o}{.}\PYG{n}{py}  \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{n}{odml} \PYG{o}{\PYGZhy{}}\PYG{n}{md} \PYG{o}{/}\PYG{n}{home}\PYG{o}{/}\PYG{n}{weltgeischt}\PYG{o}{/}\PYG{n}{EAdetection\PYGZus{}tutorial}\PYG{o}{/}\PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

The file generated is called \sphinxstyleemphasis{my\_recording\_\_metadata\_diagnostics.xml} and also resides in the main results folder.
As you see, now the file incorporates both, the diagnostic metrics from {\hyperref[\detokenize{access_metadata:example1-meta}]{\sphinxcrossref{\DUrole{std,std-ref}{Example 1}}}}, and the metadata from {\hyperref[\detokenize{access_metadata:example2-meta}]{\sphinxcrossref{\DUrole{std,std-ref}{Example 2}}}}:

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=500\sphinxpxdimen]{{md_metadataAndDiagnostics_odml}.png}\hspace*{\fill}}


\section{YAML}
\label{\detokenize{access_metadata:yaml}}\label{\detokenize{access_metadata:metayml}}
For the output format \sphinxstylestrong{yaml} it works exactly the same as described for odML in the previous section, i.e. you can use
option \sphinxtitleref{-d}, \sphinxtitleref{-m} or \sphinxtitleref{-md}. For example, to get the diagnostic metrics you type:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{n}{python} \PYG{n}{runthrough}\PYG{o}{/}\PYG{n}{metadata\PYGZus{}diagnostics}\PYG{o}{.}\PYG{n}{py} \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{format}\PYG{o}{=}\PYG{n}{yaml} \PYG{o}{\PYGZhy{}}\PYG{n}{d} \PYG{o}{/}\PYG{n}{home}\PYG{o}{/}\PYG{n}{weltgeischt}\PYG{o}{/}\PYG{n}{EAdetection\PYGZus{}tutorial}\PYG{o}{/}\PYG{n}{run\PYGZus{}params}\PYG{o}{/}\PYG{n}{my\PYGZus{}recording\PYGZus{}params}\PYG{o}{.}\PYG{n}{yml}
\end{sphinxVerbatim}

This generates a file \sphinxstyleemphasis{my\_recording\_\_diagnostics.yml} in the results folder. Just open this file with some basic text editor (by clicking on it):

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=700\sphinxpxdimen]{{md_diagnostics_yml}.png}\hspace*{\fill}}

If you are not in the mood of {\hyperref[\detokenize{access_results:access-results}]{\sphinxcrossref{\DUrole{std,std-ref}{accessing the results through matlab or python}}}}, you can conveniently read some essential diagnostic
metrics from this file.


\chapter{Todolist}
\label{\detokenize{index:todolist}}
\begin{sphinxadmonition}{note}{Todo:}
\sphinxstyleemphasis{paper\_} link
\end{sphinxadmonition}

(The {\hyperref[\detokenize{access_results:index-0}]{\sphinxcrossref{\sphinxstyleemphasis{original entry}}}} is located in /home/weltgeischt/workspace/EAdet\_doc/doc/access\_results.rst, line 103.)

\begin{sphinxadmonition}{note}{Todo:}
Link to the \sphinxstyleemphasis{paper\_}
\end{sphinxadmonition}

(The {\hyperref[\detokenize{LFP_to_bursts:index-0}]{\sphinxcrossref{\sphinxstyleemphasis{original entry}}}} is located in /home/weltgeischt/workspace/EAdet\_doc/doc/LFP\_to\_bursts.rst, line 57.)

\begin{sphinxadmonition}{note}{Todo:}
Links for \sphinxstyleemphasis{paper\_Figure XXX\_} and \sphinxstyleemphasis{paper\_}, in the whole section
\end{sphinxadmonition}

(The {\hyperref[\detokenize{output:index-0}]{\sphinxcrossref{\sphinxstyleemphasis{original entry}}}} is located in /home/weltgeischt/workspace/EAdet\_doc/doc/output.rst, line 201.)

\begin{sphinxadmonition}{note}{Todo:}
Make a link to \sphinxstyleemphasis{download this example .smr file\_}.
\end{sphinxadmonition}

(The {\hyperref[\detokenize{setting_parameters:index-0}]{\sphinxcrossref{\sphinxstyleemphasis{original entry}}}} is located in /home/weltgeischt/workspace/EAdet\_doc/doc/setting\_parameters.rst, line 134.)

\begin{sphinxadmonition}{note}{Todo:}\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi )}
\makeatletter\def\p@enumii{\p@enumi \theenumi )}\makeatother
\item {} 
Make a link to Heining et al. 2021 once the paper is out.

\item {} 
Make a link to the tutorial data file.

\item {} 
Make a link to the pdf.

\end{enumerate}
\end{sphinxadmonition}

(The {\hyperref[\detokenize{index:index-0}]{\sphinxcrossref{\sphinxstyleemphasis{original entry}}}} is located in /home/weltgeischt/workspace/EAdet\_doc/doc/index.rst, line 42.)



\renewcommand{\indexname}{Index}
\printindex
\end{document}